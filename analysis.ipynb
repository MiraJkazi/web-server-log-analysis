{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3551217",
   "metadata": {},
   "source": [
    "# Web Server Log Analysis - Python Take-Home Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb0efa",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This assessment involves analyzing the Calgary HTTP dataset, which contains approximately one year's worth of HTTP requests to the University of Calgary's Computer Science web server. You'll work with real-world web server log data to extract meaningful insights and demonstrate your Python data analysis skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81debeba",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e728b83",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Work in the cells below - You can add as many cells as needed for data loading, cleaning, and exploration\n",
    "* Import required libraries\n",
    "* Implement data loading and cleaning - Create functions to download, parse, and clean the log data\n",
    "* Explore the data - Understand the structure and identify any data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c05313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write your code here for data loading, cleaning, and exploration. Add cells as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ffe4f8-f863-4162-978d-1eaf530fe471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libaries\n",
    "\n",
    "import pandas as pd\n",
    "import apache_log_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff4520e-edf8-4c4e-9f1b-1eeef5571ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the log_format\n",
    "\n",
    "log_format = '%h %l %u %t \"%r\" %>s %b' \n",
    "\n",
    "# Create a log parser\n",
    "\n",
    "parser = apache_log_parser.make_parser(log_format)\n",
    "\n",
    "# Creating a empty list to insert data\n",
    "\n",
    "log_data = []\n",
    "\n",
    "# Log parsing process\n",
    "\n",
    "with open('calgary_access_log', 'r', encoding='utf-8', errors='replace') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            parsed_log = parser(line)\n",
    "            log_data.append(parsed_log)\n",
    "        except Exception as e:\n",
    "            \n",
    "            continue\n",
    "df = pd.DataFrame(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1975cf1b-a071-4f2b-8d12-5c1082dd4c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remote_host</th>\n",
       "      <th>remote_logname</th>\n",
       "      <th>remote_user</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_received_datetimeobj</th>\n",
       "      <th>time_received_isoformat</th>\n",
       "      <th>time_received_tz_datetimeobj</th>\n",
       "      <th>time_received_tz_isoformat</th>\n",
       "      <th>time_received_utc_datetimeobj</th>\n",
       "      <th>time_received_utc_isoformat</th>\n",
       "      <th>...</th>\n",
       "      <th>request_url_fragment</th>\n",
       "      <th>request_url_username</th>\n",
       "      <th>request_url_password</th>\n",
       "      <th>request_url_hostname</th>\n",
       "      <th>request_url_port</th>\n",
       "      <th>request_url_query_dict</th>\n",
       "      <th>request_url_query_list</th>\n",
       "      <th>request_url_query_simple_dict</th>\n",
       "      <th>status</th>\n",
       "      <th>response_bytes_clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[24/Oct/1994:13:41:41 -0600]</td>\n",
       "      <td>1994-10-24 13:41:41</td>\n",
       "      <td>1994-10-24T13:41:41</td>\n",
       "      <td>1994-10-24 13:41:41-06:00</td>\n",
       "      <td>1994-10-24T13:41:41-06:00</td>\n",
       "      <td>1994-10-24 19:41:41+00:00</td>\n",
       "      <td>1994-10-24T19:41:41+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>local</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[24/Oct/1994:13:41:41 -0600]</td>\n",
       "      <td>1994-10-24 13:41:41</td>\n",
       "      <td>1994-10-24T13:41:41</td>\n",
       "      <td>1994-10-24 13:41:41-06:00</td>\n",
       "      <td>1994-10-24T13:41:41-06:00</td>\n",
       "      <td>1994-10-24 19:41:41+00:00</td>\n",
       "      <td>1994-10-24T19:41:41+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>200</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>local</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[24/Oct/1994:13:43:13 -0600]</td>\n",
       "      <td>1994-10-24 13:43:13</td>\n",
       "      <td>1994-10-24T13:43:13</td>\n",
       "      <td>1994-10-24 13:43:13-06:00</td>\n",
       "      <td>1994-10-24T13:43:13-06:00</td>\n",
       "      <td>1994-10-24 19:43:13+00:00</td>\n",
       "      <td>1994-10-24T19:43:13+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>200</td>\n",
       "      <td>3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>local</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[24/Oct/1994:13:43:14 -0600]</td>\n",
       "      <td>1994-10-24 13:43:14</td>\n",
       "      <td>1994-10-24T13:43:14</td>\n",
       "      <td>1994-10-24 13:43:14-06:00</td>\n",
       "      <td>1994-10-24T13:43:14-06:00</td>\n",
       "      <td>1994-10-24 19:43:14+00:00</td>\n",
       "      <td>1994-10-24T19:43:14+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>200</td>\n",
       "      <td>2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>local</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[24/Oct/1994:13:43:15 -0600]</td>\n",
       "      <td>1994-10-24 13:43:15</td>\n",
       "      <td>1994-10-24T13:43:15</td>\n",
       "      <td>1994-10-24 13:43:15-06:00</td>\n",
       "      <td>1994-10-24T13:43:15-06:00</td>\n",
       "      <td>1994-10-24 19:43:15+00:00</td>\n",
       "      <td>1994-10-24T19:43:15+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>200</td>\n",
       "      <td>36403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  remote_host remote_logname remote_user                 time_received  \\\n",
       "0       local              -           -  [24/Oct/1994:13:41:41 -0600]   \n",
       "1       local              -           -  [24/Oct/1994:13:41:41 -0600]   \n",
       "2       local              -           -  [24/Oct/1994:13:43:13 -0600]   \n",
       "3       local              -           -  [24/Oct/1994:13:43:14 -0600]   \n",
       "4       local              -           -  [24/Oct/1994:13:43:15 -0600]   \n",
       "\n",
       "  time_received_datetimeobj time_received_isoformat  \\\n",
       "0       1994-10-24 13:41:41     1994-10-24T13:41:41   \n",
       "1       1994-10-24 13:41:41     1994-10-24T13:41:41   \n",
       "2       1994-10-24 13:43:13     1994-10-24T13:43:13   \n",
       "3       1994-10-24 13:43:14     1994-10-24T13:43:14   \n",
       "4       1994-10-24 13:43:15     1994-10-24T13:43:15   \n",
       "\n",
       "  time_received_tz_datetimeobj time_received_tz_isoformat  \\\n",
       "0    1994-10-24 13:41:41-06:00  1994-10-24T13:41:41-06:00   \n",
       "1    1994-10-24 13:41:41-06:00  1994-10-24T13:41:41-06:00   \n",
       "2    1994-10-24 13:43:13-06:00  1994-10-24T13:43:13-06:00   \n",
       "3    1994-10-24 13:43:14-06:00  1994-10-24T13:43:14-06:00   \n",
       "4    1994-10-24 13:43:15-06:00  1994-10-24T13:43:15-06:00   \n",
       "\n",
       "  time_received_utc_datetimeobj time_received_utc_isoformat  ...  \\\n",
       "0     1994-10-24 19:41:41+00:00   1994-10-24T19:41:41+00:00  ...   \n",
       "1     1994-10-24 19:41:41+00:00   1994-10-24T19:41:41+00:00  ...   \n",
       "2     1994-10-24 19:43:13+00:00   1994-10-24T19:43:13+00:00  ...   \n",
       "3     1994-10-24 19:43:14+00:00   1994-10-24T19:43:14+00:00  ...   \n",
       "4     1994-10-24 19:43:15+00:00   1994-10-24T19:43:15+00:00  ...   \n",
       "\n",
       "  request_url_fragment request_url_username request_url_password  \\\n",
       "0                                      None                 None   \n",
       "1                                      None                 None   \n",
       "2                                      None                 None   \n",
       "3                                      None                 None   \n",
       "4                                      None                 None   \n",
       "\n",
       "  request_url_hostname request_url_port request_url_query_dict  \\\n",
       "0                 None             None                     {}   \n",
       "1                 None             None                     {}   \n",
       "2                 None             None                     {}   \n",
       "3                 None             None                     {}   \n",
       "4                 None             None                     {}   \n",
       "\n",
       "  request_url_query_list request_url_query_simple_dict status  \\\n",
       "0                     []                            {}    200   \n",
       "1                     []                            {}    200   \n",
       "2                     []                            {}    200   \n",
       "3                     []                            {}    200   \n",
       "4                     []                            {}    200   \n",
       "\n",
       "  response_bytes_clf  \n",
       "0                150  \n",
       "1               1210  \n",
       "2               3185  \n",
       "3               2555  \n",
       "4              36403  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320bd82-265c-4015-9e89-77737930ed97",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "* Parse timestamp strings into `datetime` objects\n",
    "* Extract file extensions from the filename field\n",
    "* Handle missing or malformed data entries\n",
    "* Convert data types appropriately (integers, strings, etc.)\n",
    "* Remove or flag invalid log entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0b467794-8fcf-4fc6-9a6c-e066507ed649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string to date format\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['time_received_datetimeobj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a712d4ea-5f0a-4b19-a59f-f1052d4affdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract extension from request url\n",
    "import os\n",
    "df['extension'] = df['request_url'].apply(lambda x: os.path.splitext(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777afa35-f134-4066-a959-79428a4f5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ffd573-4fa7-457a-9aec-75c0743af3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = pd.to_numeric(df['status'], errors='coerce')\n",
    "df['response_bytes_clf'] = pd.to_numeric(df['response_bytes_clf'], errors='coerce')\n",
    "df['remote_host'] = df['remote_host'].astype('category')\n",
    "df['remote_user'] = df['remote_user'].astype('category')\n",
    "df['extension'] = df['extension'].astype(str)\n",
    "df['request_url'] = df['request_url'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2db588b1-acd8-4199-9b3b-faca2e63fccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 724910 entries, 0 to 724909\n",
      "Data columns (total 30 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   remote_host                    724910 non-null  category      \n",
      " 1   remote_logname                 724910 non-null  object        \n",
      " 2   remote_user                    724910 non-null  category      \n",
      " 3   time_received                  724910 non-null  object        \n",
      " 4   time_received_datetimeobj      724910 non-null  datetime64[ns]\n",
      " 5   time_received_isoformat        724910 non-null  object        \n",
      " 6   time_received_tz_datetimeobj   724910 non-null  object        \n",
      " 7   time_received_tz_isoformat     724910 non-null  object        \n",
      " 8   time_received_utc_datetimeobj  724910 non-null  object        \n",
      " 9   time_received_utc_isoformat    724910 non-null  object        \n",
      " 10  request_first_line             724910 non-null  object        \n",
      " 11  request_method                 724910 non-null  object        \n",
      " 12  request_url                    724910 non-null  object        \n",
      " 13  request_http_ver               723115 non-null  object        \n",
      " 14  request_url_scheme             724910 non-null  object        \n",
      " 15  request_url_netloc             724910 non-null  object        \n",
      " 16  request_url_path               724910 non-null  object        \n",
      " 17  request_url_query              724910 non-null  object        \n",
      " 18  request_url_fragment           724910 non-null  object        \n",
      " 19  request_url_username           0 non-null       object        \n",
      " 20  request_url_password           0 non-null       object        \n",
      " 21  request_url_hostname           0 non-null       object        \n",
      " 22  request_url_port               0 non-null       object        \n",
      " 23  request_url_query_dict         724910 non-null  object        \n",
      " 24  request_url_query_list         724910 non-null  object        \n",
      " 25  request_url_query_simple_dict  724910 non-null  object        \n",
      " 26  status                         724910 non-null  int64         \n",
      " 27  response_bytes_clf             666804 non-null  float64       \n",
      " 28  extension                      724910 non-null  object        \n",
      " 29  filename                       724910 non-null  object        \n",
      "dtypes: category(2), datetime64[ns](1), float64(1), int64(1), object(25)\n",
      "memory usage: 156.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d05e9a27-8e51-445a-ab55-11ad0b64d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invaild entries\n",
    "df_clean = df.dropna(subset=['time_received_datetimeobj', 'status', 'response_bytes_clf', 'request_url', 'extension'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e491a4e",
   "metadata": {},
   "source": [
    "## ⚠️ IMPORTANT: Template Questions Section\n",
    "**DO NOT MODIFY THE TEMPLATE BELOW THIS POINT**\n",
    "\n",
    "The following section contains the assessment questions. You may add cells above this section for data loading, cleaning, and exploration, but do not modify the function signatures or structure of the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da5c6e",
   "metadata": {},
   "source": [
    "## Part 2: Analysis Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1ce65",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* Implement each function according to its docstring specifications\n",
    "* Use the cleaned data you prepared in Part 1\n",
    "* Ensure your functions return the exact data types specified\n",
    "* Test your functions to verify they work correctly\n",
    "* You may add helper functions, but keep the main function signatures unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff13fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q1: Count of total log records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f6264dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer :\n",
      "666804\n"
     ]
    }
   ],
   "source": [
    "def total_log_records(df) -> int:\n",
    "    \"\"\"\n",
    "    Q1: Count of total log records.\n",
    "\n",
    "    Objective:\n",
    "        Determine the total number of HTTP log entries in the dataset.\n",
    "        Each line in the log file represents one HTTP request.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of log entries.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count log records\n",
    "\n",
    "    return len(df)  # Placeholder return\n",
    "\n",
    "\n",
    "answer1 = total_log_records(df_clean)\n",
    "print(\"Answer :\")\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5141e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q2: Count of unique hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fcbccae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def unique_host_count(df) -> int:\n",
    "    \"\"\"\n",
    "    Q2: Count of unique hosts.\n",
    "\n",
    "    Objective:\n",
    "        Determine how many distinct hosts accessed the server.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of unique hosts.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count unique hosts\n",
    "\n",
    "    return df['remote_host'].nunique()  # Placeholder return\n",
    "\n",
    "\n",
    "answer2 = unique_host_count(df_clean)\n",
    "print(\"Answer 2:\")\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c224d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q3: Date-wise unique filename counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac11c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4744\\2167715360.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['datetime'] = pd.to_datetime(df['time_received_datetimeobj'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 3:\n",
      "{'01-Apr-1995': 408, '01-Aug-1995': 621, '01-Dec-1994': 261, '01-Feb-1995': 582, '01-Jan-1995': 86, '01-Jul-1995': 297, '01-Jun-1995': 572, '01-Mar-1995': 556, '01-May-1995': 454, '01-Nov-1994': 392, '01-Oct-1995': 526, '01-Sep-1995': 320, '02-Apr-1995': 435, '02-Aug-1995': 765, '02-Dec-1994': 312, '02-Feb-1995': 502, '02-Jan-1995': 138, '02-Jul-1995': 345, '02-Jun-1995': 495, '02-Mar-1995': 576, '02-May-1995': 681, '02-Nov-1994': 410, '02-Oct-1995': 828, '02-Sep-1995': 351, '03-Apr-1995': 746, '03-Aug-1995': 558, '03-Dec-1994': 172, '03-Feb-1995': 539, '03-Jan-1995': 297, '03-Jul-1995': 424, '03-Jun-1995': 381, '03-Mar-1995': 499, '03-May-1995': 597, '03-Nov-1994': 431, '03-Oct-1995': 823, '03-Sep-1995': 207, '04-Apr-1995': 773, '04-Aug-1995': 667, '04-Dec-1994': 201, '04-Feb-1995': 542, '04-Jan-1995': 326, '04-Jul-1995': 588, '04-Jun-1995': 345, '04-Mar-1995': 391, '04-May-1995': 659, '04-Nov-1994': 384, '04-Oct-1995': 877, '04-Sep-1995': 334, '05-Apr-1995': 844, '05-Aug-1995': 471, '05-Dec-1994': 327, '05-Feb-1995': 469, '05-Jan-1995': 253, '05-Jul-1995': 583, '05-Jun-1995': 480, '05-Mar-1995': 458, '05-May-1995': 581, '05-Nov-1994': 189, '05-Oct-1995': 812, '05-Sep-1995': 408, '06-Apr-1995': 656, '06-Aug-1995': 429, '06-Dec-1994': 297, '06-Feb-1995': 611, '06-Jan-1995': 200, '06-Jul-1995': 500, '06-Jun-1995': 639, '06-Mar-1995': 612, '06-May-1995': 488, '06-Nov-1994': 211, '06-Oct-1995': 833, '06-Sep-1995': 527, '07-Apr-1995': 715, '07-Aug-1995': 579, '07-Dec-1994': 378, '07-Feb-1995': 673, '07-Jan-1995': 154, '07-Jul-1995': 413, '07-Jun-1995': 470, '07-Mar-1995': 723, '07-May-1995': 706, '07-Nov-1994': 371, '07-Oct-1995': 419, '07-Sep-1995': 554, '08-Apr-1995': 514, '08-Aug-1995': 617, '08-Dec-1994': 334, '08-Feb-1995': 603, '08-Jan-1995': 205, '08-Jul-1995': 271, '08-Jun-1995': 625, '08-Mar-1995': 623, '08-May-1995': 664, '08-Nov-1994': 262, '08-Oct-1995': 501, '08-Sep-1995': 731, '09-Apr-1995': 583, '09-Aug-1995': 652, '09-Dec-1994': 355, '09-Feb-1995': 669, '09-Jan-1995': 348, '09-Jul-1995': 225, '09-Jun-1995': 451, '09-Mar-1995': 722, '09-May-1995': 747, '09-Nov-1994': 326, '09-Oct-1995': 730, '09-Sep-1995': 386, '10-Apr-1995': 728, '10-Aug-1995': 624, '10-Dec-1994': 149, '10-Feb-1995': 690, '10-Jan-1995': 362, '10-Jul-1995': 483, '10-Jun-1995': 319, '10-Mar-1995': 668, '10-May-1995': 769, '10-Nov-1994': 341, '10-Oct-1995': 821, '10-Sep-1995': 434, '11-Apr-1995': 794, '11-Aug-1995': 447, '11-Dec-1994': 198, '11-Feb-1995': 348, '11-Jan-1995': 355, '11-Jul-1995': 554, '11-Jun-1995': 290, '11-Mar-1995': 452, '11-May-1995': 575, '11-Nov-1994': 285, '11-Oct-1995': 706, '11-Sep-1995': 687, '12-Apr-1995': 847, '12-Aug-1995': 329, '12-Dec-1994': 382, '12-Feb-1995': 480, '12-Jan-1995': 422, '12-Jul-1995': 444, '12-Jun-1995': 509, '12-Mar-1995': 475, '12-May-1995': 452, '12-Nov-1994': 160, '12-Sep-1995': 674, '13-Apr-1995': 576, '13-Aug-1995': 452, '13-Dec-1994': 388, '13-Feb-1995': 630, '13-Jan-1995': 410, '13-Jul-1995': 480, '13-Jun-1995': 454, '13-Mar-1995': 816, '13-May-1995': 280, '13-Nov-1994': 165, '13-Sep-1995': 727, '14-Apr-1995': 349, '14-Aug-1995': 538, '14-Dec-1994': 286, '14-Feb-1995': 684, '14-Jan-1995': 183, '14-Jul-1995': 533, '14-Jun-1995': 552, '14-Mar-1995': 755, '14-May-1995': 316, '14-Nov-1994': 302, '14-Sep-1995': 684, '15-Apr-1995': 404, '15-Aug-1995': 451, '15-Dec-1994': 272, '15-Feb-1995': 769, '15-Jan-1995': 204, '15-Jul-1995': 367, '15-Jun-1995': 454, '15-Mar-1995': 897, '15-May-1995': 555, '15-Nov-1994': 308, '15-Sep-1995': 674, '16-Apr-1995': 417, '16-Aug-1995': 504, '16-Dec-1994': 372, '16-Feb-1995': 634, '16-Jan-1995': 421, '16-Jul-1995': 282, '16-Jun-1995': 520, '16-Mar-1995': 581, '16-May-1995': 413, '16-Nov-1994': 368, '16-Sep-1995': 542, '17-Apr-1995': 418, '17-Aug-1995': 524, '17-Dec-1994': 285, '17-Feb-1995': 522, '17-Jan-1995': 359, '17-Jul-1995': 522, '17-Jun-1995': 375, '17-Mar-1995': 489, '17-May-1995': 492, '17-Nov-1994': 438, '17-Sep-1995': 454, '18-Apr-1995': 431, '18-Aug-1995': 475, '18-Dec-1994': 317, '18-Feb-1995': 523, '18-Jan-1995': 374, '18-Jul-1995': 545, '18-Jun-1995': 351, '18-Mar-1995': 406, '18-May-1995': 504, '18-Nov-1994': 402, '18-Sep-1995': 614, '19-Apr-1995': 678, '19-Aug-1995': 363, '19-Dec-1994': 339, '19-Feb-1995': 359, '19-Jan-1995': 460, '19-Jul-1995': 459, '19-Jun-1995': 585, '19-Mar-1995': 340, '19-May-1995': 481, '19-Nov-1994': 189, '19-Sep-1995': 706, '20-Apr-1995': 555, '20-Aug-1995': 375, '20-Dec-1994': 309, '20-Feb-1995': 484, '20-Jan-1995': 482, '20-Jul-1995': 536, '20-Jun-1995': 516, '20-Mar-1995': 656, '20-May-1995': 238, '20-Nov-1994': 253, '20-Sep-1995': 792, '21-Apr-1995': 676, '21-Aug-1995': 603, '21-Dec-1994': 265, '21-Feb-1995': 435, '21-Jan-1995': 253, '21-Jul-1995': 631, '21-Jun-1995': 609, '21-Mar-1995': 740, '21-May-1995': 275, '21-Nov-1994': 329, '21-Sep-1995': 749, '22-Apr-1995': 419, '22-Aug-1995': 503, '22-Dec-1994': 255, '22-Feb-1995': 671, '22-Jan-1995': 271, '22-Jul-1995': 428, '22-Jun-1995': 611, '22-Mar-1995': 576, '22-May-1995': 455, '22-Nov-1994': 345, '22-Sep-1995': 592, '23-Apr-1995': 314, '23-Aug-1995': 640, '23-Dec-1994': 175, '23-Feb-1995': 599, '23-Jan-1995': 414, '23-Jul-1995': 454, '23-Jun-1995': 540, '23-Mar-1995': 721, '23-May-1995': 541, '23-Nov-1994': 310, '23-Sep-1995': 481, '24-Apr-1995': 507, '24-Aug-1995': 564, '24-Dec-1994': 61, '24-Feb-1995': 503, '24-Jan-1995': 410, '24-Jul-1995': 531, '24-Jun-1995': 385, '24-Mar-1995': 495, '24-May-1995': 469, '24-Nov-1994': 353, '24-Oct-1994': 226, '24-Sep-1995': 569, '25-Apr-1995': 543, '25-Aug-1995': 583, '25-Dec-1994': 66, '25-Feb-1995': 449, '25-Jan-1995': 406, '25-Jul-1995': 558, '25-Jun-1995': 573, '25-Mar-1995': 581, '25-May-1995': 458, '25-Nov-1994': 315, '25-Oct-1994': 298, '25-Sep-1995': 712, '26-Apr-1995': 594, '26-Aug-1995': 387, '26-Dec-1994': 98, '26-Feb-1995': 374, '26-Jan-1995': 371, '26-Jul-1995': 577, '26-Jun-1995': 609, '26-Mar-1995': 509, '26-May-1995': 413, '26-Nov-1994': 216, '26-Oct-1994': 339, '26-Sep-1995': 831, '27-Apr-1995': 596, '27-Aug-1995': 427, '27-Dec-1994': 192, '27-Feb-1995': 509, '27-Jan-1995': 431, '27-Jul-1995': 558, '27-Jun-1995': 502, '27-Mar-1995': 789, '27-May-1995': 237, '27-Nov-1994': 181, '27-Oct-1994': 365, '27-Sep-1995': 796, '28-Apr-1995': 622, '28-Aug-1995': 519, '28-Dec-1994': 125, '28-Feb-1995': 493, '28-Jan-1995': 397, '28-Jul-1995': 537, '28-Jun-1995': 547, '28-Mar-1995': 792, '28-May-1995': 193, '28-Nov-1994': 329, '28-Oct-1994': 373, '28-Sep-1995': 818, '29-Apr-1995': 434, '29-Aug-1995': 495, '29-Dec-1994': 124, '29-Jan-1995': 355, '29-Jul-1995': 310, '29-Jun-1995': 456, '29-Mar-1995': 827, '29-May-1995': 450, '29-Nov-1994': 435, '29-Oct-1994': 285, '29-Sep-1995': 804, '30-Apr-1995': 272, '30-Aug-1995': 555, '30-Dec-1994': 128, '30-Jan-1995': 537, '30-Jul-1995': 449, '30-Jun-1995': 442, '30-Mar-1995': 813, '30-May-1995': 522, '30-Nov-1994': 344, '30-Oct-1994': 245, '30-Sep-1995': 619, '31-Aug-1995': 497, '31-Dec-1994': 91, '31-Jan-1995': 485, '31-Jul-1995': 596, '31-Mar-1995': 707, '31-May-1995': 542, '31-Oct-1994': 339}\n"
     ]
    }
   ],
   "source": [
    "def datewise_unique_filename_counts(df) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Q3: Date-wise unique filename counts.\n",
    "\n",
    "    Objective:\n",
    "        For each date, count the number of unique filenames that accessed the server.\n",
    "        The date should be in 'dd-MMM-yyyy' format (e.g., '01-Jul-1995').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each date to its count of unique filenames.\n",
    "              Example: {'01-Jul-1995': 123, '02-Jul-1995': 150}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for date-wise unique filename counts\n",
    "    df['datetime'] = pd.to_datetime(df['time_received_datetimeobj'], errors='coerce')\n",
    "    df = df.dropna(subset=['datetime', 'request_url'])\n",
    "    df['date_str'] = df['datetime'].dt.strftime('%d-%b-%Y')\n",
    "    result = df.groupby('date_str')['request_url'].nunique().to_dict()\n",
    "\n",
    "    return result  # Placeholder return\n",
    "\n",
    "\n",
    "answer3 = datewise_unique_filename_counts(df_clean)\n",
    "print(\"Answer 3:\")\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2da36a",
   "metadata": {},
   "source": [
    "### Q4: Number of 404 response codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d0671865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 4:\n",
      "23586\n"
     ]
    }
   ],
   "source": [
    "def count_404_errors(df) -> int:\n",
    "    \"\"\"\n",
    "    Q4: Number of 404 response codes.\n",
    "\n",
    "    Objective:\n",
    "        Count how many times the HTTP 404 Not Found status appears in the logs.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of 404 errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count 404 errors\n",
    "    \n",
    "\n",
    "    return (df['status'] == 404).sum()  # Placeholder return\n",
    "\n",
    "\n",
    "answer4 = count_404_errors(df)\n",
    "print(\"Answer 4:\")\n",
    "\n",
    "print(answer4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73928d2",
   "metadata": {},
   "source": [
    "### Q5: Top 15 filenames with 404 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "358f0523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 5:\n",
      "[('index.html', 4691), ('4115.html', 900), ('1611.html', 649), ('5698.xbm', 585), ('710.txt', 408), ('2002.html', 257), ('2177.gif', 193), ('10695.ps', 161), ('6555.html', 153), ('487.gif', 152), ('151.html', 149), ('488.gif', 148), ('3414.gif', 148), ('40.html', 148), ('9678.gif', 142)]\n"
     ]
    }
   ],
   "source": [
    "def top_15_filenames_with_404(df : str, n : int) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q5: Top 15 filenames with 404 responses.\n",
    "\n",
    "    Objective:\n",
    "        Identify which requested URLs most frequently resulted in a 404 error.\n",
    "        Return the top 15 filenames sorted by frequency.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
    "              Example: [('index.html', 200), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 15 filenames with 404\n",
    "    filename_counts = (df[df['status'] == 404]['request_url']).value_counts().head(n)\n",
    "\n",
    "    return list(filename_counts.items())  # Placeholder return\n",
    "\n",
    "\n",
    "answer5 = top_15_filenames_with_404(df, 15)\n",
    "print(\"Answer 5:\")\n",
    "print(answer5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328c88a",
   "metadata": {},
   "source": [
    "### Q6: Top 15 file extension with 404 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d0aca8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 6:\n",
      "[('.html', 12166), ('.gif', 7210), ('.xbm', 826), ('.ps', 757), ('.jpg', 520), ('.txt', 497), ('', 355), ('.GIF', 135), ('.htm', 108), ('.cgi', 77), ('.com', 46), ('.gif\"', 45), ('.Z', 41), ('.dvi', 40), ('.ca', 37)]\n"
     ]
    }
   ],
   "source": [
    "def top_15_ext_with_404(df, n : int) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q6: Top 15 file extensions with 404 responses.\n",
    "\n",
    "    Objective:\n",
    "        Find which file extensions generated the most 404 errors.\n",
    "        Return the top 15 sorted by number of 404s.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (extension, count), sorted by count in descending order.\n",
    "              Example: [('html', 45), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 15 extensions with 404\n",
    "    top_n_ext = df[df['status'] == 404]['extension'].value_counts().head(n)\n",
    "    return list(top_n_ext.items())  # Placeholder return\n",
    "\n",
    "\n",
    "answer6 = top_15_ext_with_404(df, 15)\n",
    "print(\"Answer 6:\")\n",
    "print(answer6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52c8ba",
   "metadata": {},
   "source": [
    "### Q7: Total bandwidth transferred per day for the month of July 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "45f52d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 7:\n",
      "{'01 Jul 1995': 11349799, '02 Jul 1995': 8656918, '03 Jul 1995': 13596612, '04 Jul 1995': 26573988, '05 Jul 1995': 19541225, '06 Jul 1995': 19755015, '07 Jul 1995': 9427822, '08 Jul 1995': 5403491, '09 Jul 1995': 4660556, '10 Jul 1995': 14917754, '11 Jul 1995': 22507207, '12 Jul 1995': 17367065, '13 Jul 1995': 15989234, '14 Jul 1995': 19186430, '15 Jul 1995': 15773233, '16 Jul 1995': 9016378, '17 Jul 1995': 19601338, '18 Jul 1995': 17099761, '19 Jul 1995': 17851725, '20 Jul 1995': 20752623, '21 Jul 1995': 25491617, '22 Jul 1995': 8136259, '23 Jul 1995': 9593870, '24 Jul 1995': 22308265, '25 Jul 1995': 24561635, '26 Jul 1995': 24995540, '27 Jul 1995': 25969995, '28 Jul 1995': 36460693, '29 Jul 1995': 11700624, '30 Jul 1995': 23189598, '31 Jul 1995': 30730715}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14832\\3596242896.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_july['date_str'] = df_july['time_received_datetimeobj'].dt.strftime('%d %b %Y')\n"
     ]
    }
   ],
   "source": [
    "def total_bandwidth_per_day(df) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Q7: Total bandwidth transferred per day for the month of July 1995.\n",
    "\n",
    "    Objective:\n",
    "        Sum the number of bytes transferred per day.\n",
    "        Skip entries where the byte field is missing or '-'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each date to total bytes transferred.\n",
    "              Example: {'01-Jul-1995': 123456789, ...}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to compute total bandwidth per day\n",
    "    df.dropna(subset= ['response_bytes_clf', 'time_received_datetimeobj'])\n",
    "\n",
    "    df_july = df[df['time_received_datetimeobj'].dt.strftime('%b %Y') == 'Jul 1995']\n",
    "\n",
    "    df_july['date_str'] = df_july['time_received_datetimeobj'].dt.strftime('%d %b %Y')\n",
    "    bandwidth_by_date = df_july.groupby('date_str')['response_bytes_clf'].sum().astype(int)\n",
    "\n",
    "    return bandwidth_by_date.to_dict()  # Placeholder return\n",
    "\n",
    "\n",
    "answer7 = total_bandwidth_per_day(df_clean)\n",
    "print(\"Answer 7:\")\n",
    "print(answer7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc00908",
   "metadata": {},
   "source": [
    "### Q8: Hourly request distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a77f3e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 8:\n",
      "{0: 17206, 1: 13196, 2: 11733, 3: 10027, 4: 9369, 5: 10143, 6: 12280, 7: 15550, 8: 24664, 9: 31115, 10: 39713, 11: 43766, 12: 43085, 13: 47338, 14: 50087, 15: 46337, 16: 46849, 17: 41378, 18: 30435, 19: 28219, 20: 27169, 21: 25109, 22: 21873, 23: 20163}\n"
     ]
    }
   ],
   "source": [
    "def hourly_request_distribution(df) -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Q8: Hourly request distribution.\n",
    "\n",
    "    Objective:\n",
    "        Count the number of requests made during each hour (00 to 23).\n",
    "        Useful for understanding traffic peaks.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping hour (int) to request count.\n",
    "              Example: {0: 120, 1: 90, ..., 23: 80}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for hourly distribution\n",
    "    df.dropna(subset = ['time_received_datetimeobj'])\n",
    "    hourly_req = df['time_received_datetimeobj'].dt.hour.value_counts().sort_index()\n",
    "\n",
    "    return hourly_req.to_dict()  # Placeholder return\n",
    "\n",
    "\n",
    "answer8 = hourly_request_distribution(df_clean)\n",
    "print(\"Answer 8:\")\n",
    "print(answer8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b7083",
   "metadata": {},
   "source": [
    "### Q9: Top 10 most requested filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "91168ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 9:\n",
      "[('index.html', 104045), ('3.gif', 24005), ('2.gif', 23595), ('4.gif', 8017), ('244.gif', 5144), ('5.html', 5004), ('4097.gif', 4865), ('8870.jpg', 4488), ('6733.gif', 4278), ('8472.gif', 3843)]\n"
     ]
    }
   ],
   "source": [
    "def top_10_most_requested_filenames(df, n) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q9: Top 10 most requested filenames.\n",
    "\n",
    "    Objective:\n",
    "        Identify the most commonly requested URLs (irrespective of status code).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
    "                Example: [('index.html', 500), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 10 most requested filenames\n",
    "\n",
    "    top_n_filename = df['request_url'].value_counts().head(n)\n",
    "\n",
    "    return list(top_n_filename.items())  # Placeholder return\n",
    "\n",
    "\n",
    "answer9 = top_10_most_requested_filenames(df_clean, 10)\n",
    "print(\"Answer 9:\")\n",
    "print(answer9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb4778",
   "metadata": {},
   "source": [
    "### Q10: HTTP response code distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "bd4453ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 10:\n",
      "{200: 568348, 302: 640, 304: 97792, 403: 2, 500: 22}\n"
     ]
    }
   ],
   "source": [
    "def response_code_distribution(df) -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Q10: HTTP response code distribution.\n",
    "\n",
    "    Objective:\n",
    "        Count how often each HTTP status code appears in the logs.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping HTTP status codes (as int) to their frequency.\n",
    "              Example: {200: 150000, 404: 3000}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for response code counts\n",
    "    df = df.dropna(subset=['status'])\n",
    "    count_status = df['status'].value_counts().sort_index()\n",
    "\n",
    "    return count_status.to_dict()  # Placeholder return\n",
    "\n",
    "\n",
    "answer10 = response_code_distribution(df_clean)\n",
    "print(\"Answer 10:\")\n",
    "print(answer10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bdbaf087-bf89-4467-bfda-478c18fed14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook analysis.ipynb to notebook\n",
      "[NbConvertApp] Writing 18989 bytes to analysis.ipynb\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True --inplace analysis.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
